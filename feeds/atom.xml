<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Titleless Sights</title><link href="http://james0zan.github.io/" rel="alternate"></link><link href="http://james0zan.github.io/feeds/atom.xml" rel="self"></link><id>http://james0zan.github.io/</id><updated>2013-06-07T00:00:00+08:00</updated><entry><title>Memory Barriers: a Hardware View for Software Hackers</title><link href="http://james0zan.github.io/memory-barriers-a-hardware-view-for-software-hackers.html" rel="alternate"></link><updated>2013-06-07T00:00:00+08:00</updated><author><name>Mingxing Zhang</name></author><id>tag:james0zan.github.io,2013-06-07:memory-barriers-a-hardware-view-for-software-hackers.html</id><summary type="html">&lt;p&gt;&lt;em&gt;URL:&lt;/em&gt; &lt;a class="reference external" href="http://www.rdrop.com/users/paulmck/scalability/paper/whymb.2010.07.23a.pdf"&gt;http://www.rdrop.com/users/paulmck/scalability/paper/whymb.2010.07.23a.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This paper gives a clear explanation on techniques for increasing cache utilization,
and justify the existence of memory barriers as a necessary evil that
is required to enable good performance and scalability.&lt;/p&gt;
&lt;p&gt;Its general structure is as follows:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Presents the structure of a cache;&lt;/li&gt;
&lt;li&gt;Explains how cache-coherency protocols ensure that different per-CPU caches coordinate with each other;&lt;/li&gt;
&lt;li&gt;Describes a technique called &amp;quot;store buﬀer&amp;quot;, which can be used to ease the performance loss caused by invalidate-acknowledgement message passing.&lt;/li&gt;
&lt;li&gt;Gives an example on why write memory barriers are needed -- Store buﬀers will reorder the execution of instructions to achieve better performance but we need methods to ensure some critical orders will not be undermined;&lt;/li&gt;
&lt;li&gt;Outlines another technique named &amp;quot;invalidate queue&amp;quot; for making invalidate-acknowledgement messages arrive more quickly.&lt;/li&gt;
&lt;li&gt;Gives a corresponding example on why read memory barriers are needed -- Invalidate queues will cause another kind of reordering which can be prevented by read memory barriers.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The paper also gives many quizzes and discussions on real implementations (e.g. ARM, IA64).&lt;/p&gt;
</summary><category term="cache"></category><category term="paper"></category></entry><entry><title>Scalable Event Multiplexing: epoll vs. kqueue</title><link href="http://james0zan.github.io/scalable-event-multiplexing-epoll-vs-kqueue.html" rel="alternate"></link><updated>2013-05-16T00:00:00+08:00</updated><author><name>Mingxing Zhang</name></author><id>tag:james0zan.github.io,2013-05-16:scalable-event-multiplexing-epoll-vs-kqueue.html</id><summary type="html">&lt;p&gt;&lt;em&gt;URL:&lt;/em&gt; &lt;a class="reference external" href="http://www.eecs.berkeley.edu/~sangjin/2012/12/21/epoll-vs-kqueue.html"&gt;http://www.eecs.berkeley.edu/~sangjin/2012/12/21/epoll-vs-kqueue.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This article gives a fairly good review on common event multiplexing techniques, especially the difference between epoll (in Linux) and kqueue (in BSD).&lt;/p&gt;
&lt;p&gt;There are also some interesting anecdotes enclosed in the post, such as:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Stateful event multiplexing techniques (epoll, kqueue) are derived from the &lt;a class="reference external" href="http://static.usenix.org/event/usenix99/full_papers/banga/banga.pdf"&gt;paper&lt;/a&gt; by Banga et al, published at USENIX ATC 1999.&lt;/li&gt;
&lt;li&gt;kqueue is technically superior to epoll.&lt;/li&gt;
&lt;li&gt;It is often quoted that “In Unix, everything is a file”, but it is not always true.&lt;/li&gt;
&lt;/ul&gt;
</summary><category term="epoll"></category><category term="kqueue"></category></entry><entry><title>Pitfalls of Object Oriented Programming</title><link href="http://james0zan.github.io/pitfalls-of-object-oriented-programming.html" rel="alternate"></link><updated>2013-05-15T00:00:00+08:00</updated><author><name>Mingxing Zhang</name></author><id>tag:james0zan.github.io,2013-05-15:pitfalls-of-object-oriented-programming.html</id><summary type="html">&lt;p&gt;&lt;em&gt;URL:&lt;/em&gt; &lt;a class="reference external" href="http://research.scee.net/files/presentations/gcapaustralia09/Pitfalls_of_Object_Oriented_Programming_GCAP_09.pdf"&gt;http://research.scee.net/files/presentations/gcapaustralia09/Pitfalls_of_Object_Oriented_Programming_GCAP_09.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Since the time consumed by a single CPU cycle is much lesser than RAM latency in nowadays, it becomes critical and profitable to better utilize the cache.&lt;/p&gt;
&lt;p&gt;In this slide, Tony Albrecht states that with modern hardware, excessive encapsulation in OO is BAD. According to the principle of OOP, an instantiated object will generally contain all data associated with it. But when we only need a small portion of its fileds during the calculation there may be a lot of avoidable cache misses.&lt;/p&gt;
</summary><category term="cache"></category><category term="OO"></category></entry><entry><title>Fast and accurate long-read alignment with Burrows–Wheeler transform @ BIOINFORMATICS Vol. 26 no. 5 2010</title><link href="http://james0zan.github.io/fast-and-accurate-long-read-alignment-with-burrows-wheeler-transform-bioinformatics-vol-26-no-5-2010.html" rel="alternate"></link><updated>2013-05-03T00:00:00+08:00</updated><author><name>Mingxing Zhang</name></author><id>tag:james0zan.github.io,2013-05-03:fast-and-accurate-long-read-alignment-with-burrows-wheeler-transform-bioinformatics-vol-26-no-5-2010.html</id><summary type="html">&lt;p&gt;&lt;em&gt;URL:&lt;/em&gt; &lt;a class="reference external" href="http://dl.acm.org/citation.cfm?id=1741825"&gt;http://dl.acm.org/citation.cfm?id=1741825&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;A new generation of faster methods to find DNA sequence matches was developed since 2000. They are tailored for short (&amp;lt;100 bp) reads alignment and 10–1000 times faster than general algorithms, such as BLAST. However, reads coming from the new sequencing technologies are not short any more, which makes efficiently aligning long reads against a long reference sequence a new challenge to the development of alignment tools.&lt;/p&gt;
&lt;p&gt;This paper presents Burrows-Wheeler Aligner’s Smith-Waterman Alignment (BWA-SW), a novel algorithm to align long sequences up to 1Mb against a large sequence database (e.g. the human genome) with a few gigabytes of memory. The algorithm is as accurate as SSAHA2, more accurate than BLAST, and is several to tens of times faster than both.&lt;/p&gt;
&lt;p&gt;Similar to other algorithm papers, if you are familiar with the background, it’s easy for you to grasp the core algorithm within a few minutes. So I will just recommend several supporting material here:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;First, Heng Li et al.'s previous paper &lt;a class="reference external" href="http://dl.acm.org/citation.cfm?id=1576130"&gt;&amp;quot;Fast and accurate short read alignment with Burrows–Wheeler transform&amp;quot;&lt;/a&gt; gives a more detailed explanation of the building blocks of this algorithm, such as Prefix trie and Burrows–Wheeler transform. It is a good idea to read this paper in advance.&lt;/li&gt;
&lt;li&gt;Second, if you still have trouble in understanding how FM-index works, there is an excellent diagrammatic presentation in Alex's post &lt;a class="reference external" href="http://alexbowe.com/fm-index/"&gt;&amp;quot;FM-Indexes and Backwards Search&amp;quot;&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Finally, if you have no idea what is &amp;quot;read alignment&amp;quot; but still interesting in this exquisite application of FM-index. You can read these two slides [&lt;a class="reference external" href="http://www.cs.helsinki.fi/bioinformatiikka/mbi/courses/07-08/itb/slides/itb0708_slides_83-116.pdf"&gt;1&lt;/a&gt;, &lt;a class="reference external" href="http://www.cs.helsinki.fi/bioinformatiikka/mbi/courses/07-08/itb/slides/itb0708_slides_117-142.pdf"&gt;2&lt;/a&gt;] at first.&lt;/li&gt;
&lt;/ul&gt;
</summary><category term="bioinformatics"></category><category term="paper"></category><category term="FM-index"></category></entry><entry><title>Production-Run Software Failure Diagnosis via Hardware Performance Counters @ ASPLOS'13</title><link href="http://james0zan.github.io/production-run-software-failure-diagnosis-via-hardware-performance-counters-asplos13.html" rel="alternate"></link><updated>2013-05-03T00:00:00+08:00</updated><author><name>Mingxing Zhang</name></author><id>tag:james0zan.github.io,2013-05-03:production-run-software-failure-diagnosis-via-hardware-performance-counters-asplos13.html</id><summary type="html">&lt;p&gt;&lt;em&gt;URL:&lt;/em&gt; &lt;a class="reference external" href="http://dl.acm.org/citation.cfm?id=2451128"&gt;http://dl.acm.org/citation.cfm?id=2451128&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This paper presents PBI, a system that uses existing hardware performance counters to diagnose production-run failures caused by sequential and concurrency bugs with low overhead (&amp;lt; 10%).&lt;/p&gt;
&lt;p&gt;Firstly, we must notice that this tool is used to diagnose bugs, not detect or prevent bugs during production runs. This purpose enables PBI to leverage some kinds of statistical methods. As a consequence, you must collect enough failure runs before diagnosing it, which usually requests that you should know how to trigger the bug.&lt;/p&gt;
&lt;p&gt;Then, personally, I think the most important observation in this paper is: a wide variety of common software bugs can be reflected by a small portion of hardware events supported by hardware performance counters.&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;For concurrency bugs, those events are cache-coherence events (state change in &lt;a class="reference external" href="http://en.wikipedia.org/wiki/MESI_protocol"&gt;MESI protocol&lt;/a&gt;). For example, the I-predicate and S-predicate can differentiate failure runs from success runs for all 4 types of atomicity violations. More detailed discussions can be found in Sec. 3.1.2.&lt;/li&gt;
&lt;li&gt;For sequential bugs, PBI use branch-related events, because many semantic bugs are related to wrong control flows.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This paper also proposes a statistical method to identify which events are highly correlated with failure runs.&lt;/p&gt;
</summary><category term="concurrency bug"></category><category term="paper"></category></entry><entry><title>All about Eve: Execute-Verify Replication for Multi-Core Servers @ OSDI'12</title><link href="http://james0zan.github.io/all-about-eve-execute-verify-replication-for-multi-core-servers-osdi12.html" rel="alternate"></link><updated>2013-05-02T00:00:00+08:00</updated><author><name>Mingxing Zhang</name></author><id>tag:james0zan.github.io,2013-05-02:all-about-eve-execute-verify-replication-for-multi-core-servers-osdi12.html</id><summary type="html">&lt;p&gt;&lt;em&gt;URL:&lt;/em&gt; &lt;a class="reference external" href="http://dl.acm.org/citation.cfm?id=2387903"&gt;http://dl.acm.org/citation.cfm?id=2387903&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://en.wikipedia.org/wiki/State_machine_replication"&gt;State machine replication (SMR)&lt;/a&gt; is a powerful fault tolerance technique, it enforces replicas to deterministically process the same
sequence of requests so that they produce the same sequence of outputs.&lt;/p&gt;
&lt;p&gt;But this technique doesn't suit for parallel systems, because if different servers interleave requests’ instructions in different ways, the states and outputs of correct servers may diverge even if no faults occur. As a result, most SMR systems require servers to process requests sequentially.&lt;/p&gt;
&lt;p&gt;In contrast, Eve partitions requests in batches and allows different replicas to execute requests within each batch in parallel. After each batch, it speculates that whether the results of these parallel executions (i.e. the system’s important state and output at each replica) will match across enough replicas.  If such a correct state/output can be identified, Eve makes those incorrect replicas issue an incremental state transfer request to other replicas (by leveraging  a &lt;a class="reference external" href="http://en.wikipedia.org/wiki/Merkle_signature_scheme"&gt;Merkle tree&lt;/a&gt;). However, if too many replicas diverge so that the correct state/output cannot be identified, Eve guarantees safety and liveness by rolling back and sequentially and deterministically re-executing the requests.&lt;/p&gt;
&lt;p&gt;Since diverges will seriously impair Eve's performance, it uses a &lt;em&gt;mixer&lt;/em&gt; stage to apply
&lt;strong&gt;application-specific&lt;/strong&gt; criteria to produce groups of requests that are unlikely to interfere.&lt;/p&gt;
&lt;p&gt;As a side effect, Eve is especially useful in tolerating concurrency bugs. First, Eve’s
mixer reduces the likelihood of triggering latent concurrency bugs by attempting to run only unlikely-to-interfere requests in parallel; Second, Eve's execute-verify architecture allows Eve to detect and recover when concurrency causes executions to diverge.&lt;/p&gt;
&lt;p&gt;In their experiments, Eve achieves a 2.6x ~ 6.5x speedup over traditional sequential execution replica and at most 4.7x speedup over the &lt;a class="reference external" href="http://dl.acm.org/citation.cfm?id=1387601"&gt;Remus primary-backup system&lt;/a&gt;. It also finds new concurrency bugs in H2 database.&lt;/p&gt;
</summary><category term="replica"></category><category term="parallel"></category><category term="paper"></category></entry><entry><title>Myth: Eric Brewer on Why Banks are BASE Not ACID - Availability Is Revenue</title><link href="http://james0zan.github.io/myth-eric-brewer-on-why-banks-are-base-not-acid-availability-is-revenue.html" rel="alternate"></link><updated>2013-05-02T00:00:00+08:00</updated><author><name>Mingxing Zhang</name></author><id>tag:james0zan.github.io,2013-05-02:myth-eric-brewer-on-why-banks-are-base-not-acid-availability-is-revenue.html</id><summary type="html">&lt;p&gt;&lt;em&gt;URL:&lt;/em&gt; &lt;a class="reference external" href="http://highscalability.com/blog/2013/5/1/myth-eric-brewer-on-why-banks-are-base-not-acid-availability.html"&gt;http://highscalability.com/blog/2013/5/1/myth-eric-brewer-on-why-banks-are-base-not-acid-availability.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;A refutation of the myth, &amp;quot;Money is important, so banks must use transactions to keep money safe and consistent&amp;quot;.&lt;/p&gt;
&lt;p&gt;This fact sets the grounds of  Jeff Darcy's argument, &lt;a class="reference external" href="http://pl.atyp.us/wordpress/index.php/2013/03/is-eventual-consistency-useful"&gt;&amp;quot;Is Eventual Consistency Useful?&amp;quot;&lt;/a&gt;&lt;/p&gt;
</summary><category term="CAP"></category><category term="BASE"></category></entry><entry><title>Consistency Models Explained Briefly</title><link href="http://james0zan.github.io/consistency-models-explained-briefly.html" rel="alternate"></link><updated>2013-04-27T00:00:00+08:00</updated><author><name>Mingxing Zhang</name></author><id>tag:james0zan.github.io,2013-04-27:consistency-models-explained-briefly.html</id><summary type="html">&lt;p&gt;&lt;em&gt;URL:&lt;/em&gt; &lt;a class="reference external" href="http://coldattic.info/shvedsky/pro/blogs/a-foo-walks-into-a-bar/posts/88"&gt;http://coldattic.info/shvedsky/pro/blogs/a-foo-walks-into-a-bar/posts/88&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Consistency model, which describes how far the behavior of your multi-threaded (or distributed) system is from the ideal &amp;quot;sequential behavior&amp;quot;, belongs to the most important concepts of concurrency systems. But unfortunatly, discriptions about this topic are usually incomplete and even inconsistent with each other.&lt;/p&gt;
&lt;p&gt;This article, as its title indicates, clearly explains all the important consistency models with vivid diagrammatic presentations, which is well worth reading.&lt;/p&gt;
&lt;p&gt;Its main content is following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;&amp;quot;Multithreading&amp;quot; Consistency Models&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Strong Consistency aka Linearizability&lt;/li&gt;
&lt;li&gt;Sequential Consistency&lt;/li&gt;
&lt;li&gt;Quiescent Consistency&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;&amp;quot;Distributed&amp;quot; Consistency Models&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Eventual Consistency&lt;/li&gt;
&lt;li&gt;Strict Consistency&lt;/li&gt;
&lt;li&gt;Serializability&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
</summary><category term="consistency"></category></entry><entry><title>Welcome!</title><link href="http://james0zan.github.io/index.html.html" rel="alternate"></link><updated>2013-04-27T00:00:00+08:00</updated><author><name>Mingxing Zhang</name></author><id>tag:james0zan.github.io,2013-04-27:index.html.html</id><summary type="html">&lt;p&gt;Hello, I'm Mingxing Zhang a.k.a. james0zan.&lt;/p&gt;
&lt;p&gt;Currently, I am a 1st year Ph.D. student in &lt;a class="reference external" href="http://madsys.cs.tsinghua.edu.cn/en/"&gt;MadSys Group&lt;/a&gt; &amp;#64; Tsinghua University, and my research interests lie in distributed and parallel systems. You can refer to my &lt;a class="reference external" href="http://madsys.cs.tsinghua.edu.cn/~zhangmx/"&gt;homepage&lt;/a&gt; for more information.&lt;/p&gt;
&lt;p&gt;Thank you for visiting. The blog is &lt;a class="reference external" href="category/blog.html"&gt;here&lt;/a&gt;.&lt;/p&gt;
</summary></entry><entry><title>Parallel Merge Sort</title><link href="http://james0zan.github.io/parallel-merge-sort.html" rel="alternate"></link><updated>2013-04-27T00:00:00+08:00</updated><author><name>Mingxing Zhang</name></author><id>tag:james0zan.github.io,2013-04-27:parallel-merge-sort.html</id><summary type="html">&lt;p&gt;&lt;em&gt;URL:&lt;/em&gt; &lt;a class="reference external" href="http://coldattic.info/shvedsky/pro/blogs/a-foo-walks-into-a-bar/posts/49"&gt;http://coldattic.info/shvedsky/pro/blogs/a-foo-walks-into-a-bar/posts/49&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I used to think that the &amp;quot;merge&amp;quot; step of merge sort cannot be efficiently parallelized, because the fact that an element belongs to the tail of one sorted array could not even guarrantee that it won't rank first in the other sorted arrary.&lt;/p&gt;
&lt;p&gt;But this article illustrates that we can get across this obstacle by doing some binary search in advence.&lt;/p&gt;
&lt;p&gt;And even better, this algorithm preserves merges sort's ability to be a external sort.&lt;/p&gt;
</summary><category term="parallel"></category><category term="algorithm"></category></entry><entry><title>Start Blogging Now</title><link href="http://james0zan.github.io/start-blogging-now.html" rel="alternate"></link><updated>2013-04-27T00:00:00+08:00</updated><author><name>Mingxing Zhang</name></author><id>tag:james0zan.github.io,2013-04-27:start-blogging-now.html</id><summary type="html">&lt;p&gt;Inspired and encoraged by Nathan Marz's posts [&lt;a class="reference external" href="http://nathanmarz.com/blog/you-should-blog-even-if-you-have-no-readers.html"&gt;1&lt;/a&gt;, &lt;a class="reference external" href="http://nathanmarz.com/blog/break-into-silicon-valley-with-a-blog-1.html"&gt;2&lt;/a&gt;], I made the decision to restart my blog here.
But since I'm infected with procrastination to some extent, I may only share several interesting articles with my own comments under the &amp;quot;&lt;a class="reference external" href="http://james0zan.github.io/category/bookmark.html"&gt;Bookmark&lt;/a&gt;&amp;quot; column in the begining. I hope this will help me develop a habit of writing and sharing.&lt;/p&gt;
&lt;p&gt;Actually, I have already goten some articles under crafting, but I'm not sure when I can finish them ......&lt;/p&gt;
&lt;p&gt;Thank you for your reading, and I hope that I can see you again.&lt;/p&gt;
</summary><category term="journaling"></category></entry></feed>